<document xmlns="http://cnx.rice.edu/cnxml" xmlns:m="http://www.w3.org/1998/Math/MathML" xmlns:md="http://cnx.rice.edu/mdml">
  <title>Kolmogorov Entropy</title>
  <metadata><md:content-id>undefined</md:content-id><md:title/><md:uuid>223948a5-4140-4643-86c6-df8838c0cf7f</md:uuid>
</metadata>
  <content>


<figure id="uid10"><media id="idm3417392" alt=""><image src="../../media/figure4.png" mime-type="image/png"/><image for="pdf" src="../../media/figure4.eps" mime-type="application/postscript"/></media>
<caption>Coverings of <m:math><m:mi>K</m:mi></m:math> by balls of radius
<m:math><m:mi>ϵ</m:mi></m:math>.</caption></figure>

<para id="id2247912">Given <m:math><m:mrow><m:mi>ϵ</m:mi><m:mo>&gt;</m:mo><m:mn>0</m:mn></m:mrow></m:math>, and the compact set <m:math><m:mi>K</m:mi></m:math>, consider all coverings
of <m:math><m:mi>K</m:mi></m:math> by balls of radius <m:math><m:mi>ϵ</m:mi></m:math>, as shown in
<link target-id="uid10"/>. In other words,
<equation id="id2247963"><m:math mode="display"><m:mrow><m:mi>K</m:mi><m:mo>⊆</m:mo><m:msubsup><m:mi>U</m:mi> <m:mrow><m:mi>i</m:mi><m:mo>=</m:mo><m:mn>1</m:mn></m:mrow> <m:mi>N</m:mi> </m:msubsup><m:mrow><m:mi>b</m:mi><m:mo>(</m:mo></m:mrow><m:msub><m:mi>f</m:mi> <m:mi>i</m:mi> </m:msub><m:mrow><m:mo>,</m:mo><m:mi>ϵ</m:mi><m:mo>)</m:mo><m:mo>.</m:mo></m:mrow></m:mrow></m:math></equation>
Let <m:math><m:mrow><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mo>:</m:mo><m:mo>=</m:mo><m:mtext>inf</m:mtext><m:mspace width="4.pt"/><m:mrow><m:mo>{</m:mo><m:mi>N</m:mi><m:mo>:</m:mo><m:mtext>over</m:mtext><m:mspace width="4.pt"/><m:mtext>all</m:mtext><m:mspace width="4.pt"/><m:mtext>such</m:mtext><m:mspace width="4.pt"/><m:mtext>covers</m:mtext><m:mo>}</m:mo></m:mrow></m:mrow></m:math>.
<m:math><m:mrow><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>)</m:mo></m:mrow></m:mrow></m:math> is called the covering number of <m:math><m:mi>K</m:mi></m:math>. Since it
depends on <m:math><m:mi>X</m:mi></m:math> and <m:math><m:mi>K</m:mi></m:math>, we write it as
<m:math><m:mrow><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mo>=</m:mo><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo></m:mrow></m:mrow></m:math>.</para>

<rule type="definition" id="def1"><label>Definition</label>
<title>Kolmogorov entropy</title>
<statement id="idm12505824">
<para id="id2248166">The Kolmogorov entropy, denoted by <m:math><m:mrow><m:msub><m:mi>H</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo></m:mrow></m:mrow></m:math>, of the compact set <m:math><m:mi>K</m:mi></m:math> in <m:math><m:mi>X</m:mi></m:math> is defined as the logarithm of the covering number:
<equation id="id2248223"><m:math mode="display"><m:mrow><m:msub><m:mi>H</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo></m:mrow><m:mo>=</m:mo><m:mo form="prefix">log</m:mo><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo></m:mrow><m:mo>.</m:mo></m:mrow></m:math></equation>
</para>
</statement>
</rule>

<para id="id2248280">The Kolmogorov entropy solves our problem of optimal encoding in the sense of the following theorem.</para>
<rule type="theorem" id="thm1">
<statement id="idm1870480">
<para id="id2248288">
For any compact set <m:math><m:mrow><m:mi>K</m:mi><m:mo>⊂</m:mo><m:mi>X</m:mi></m:mrow></m:math>, we have <m:math><m:mrow><m:msub><m:mi>n</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo><m:mo>=</m:mo><m:mo>⌈</m:mo></m:mrow><m:msub><m:mi>H</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mi>X</m:mi><m:mo>)</m:mo><m:mo>⌉</m:mo></m:mrow></m:mrow></m:math>, where <m:math><m:mrow><m:mo>⌈</m:mo><m:mo>·</m:mo><m:mo>⌉</m:mo></m:mrow></m:math> is the ceiling function.</para>
</statement>
<proof id="idm11559488">
<para id="id2248380">Sketch: We can define an encoder-decoder as follows
To encode: Say <m:math><m:mrow><m:mi>f</m:mi><m:mo>∈</m:mo><m:mi>K</m:mi></m:mrow></m:math>. Just specify which ball it is
covered by. Because the number of balls is <m:math><m:mrow><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mrow><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo></m:mrow><m:mover><m:munder><m:mi>X</m:mi> <m:mo>̲</m:mo></m:munder> <m:mo>¯</m:mo></m:mover><m:mrow><m:mo>)</m:mo></m:mrow></m:mrow></m:math>, we
need at most <m:math><m:mrow><m:mo>⌈</m:mo><m:mo form="prefix">log</m:mo><m:msub><m:mi>N</m:mi> <m:mi>ϵ</m:mi> </m:msub><m:mo>(</m:mo><m:mi>K</m:mi><m:mo>,</m:mo><m:mover><m:munder><m:mi>X</m:mi> <m:mo>̲</m:mo></m:munder> <m:mo>¯</m:mo></m:mover><m:mo>)</m:mo><m:mo>⌉</m:mo></m:mrow></m:math> bits to specify any such ball
ball.</para>
<para id="id2248492">To decode: Just take the center of the ball specified by the
bitstream.</para>
<para id="id2248503">It is now easy to see that this encoder-decoder pair is optimal in either of the senses given
above. <m:math><m:mo>□</m:mo></m:math></para>
</proof>
</rule>
<para id="id2248519">The above encoder is not practical. However, the Kolmogorov entropy tells us the best performance we can expect from any encoder-decoder pair. Kolmogorov entropy is defined in the deterministic setting. It is the analogue of the Shannon entropy which is defined in a stochastic setting.</para>

  </content>
</document>